{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, backend as K\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tensorflow.keras import backend as K\n",
    "#from keras.activations import softmax\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "DIR = '/home/arun/Models/'\n",
    "train = os.path.join(DIR, 'train.csv')\n",
    "test = os.path.join(DIR, 'test.csv')\n",
    "valid = os.path.join(DIR, 'validate.csv')\n",
    "\n",
    "START = 8\n",
    "TIMERANGE = 20\n",
    "TIMERANGE_TEST = 12\n",
    "TEST_START = START + TIMERANGE + 1\n",
    "\n",
    "CATCOLS = ['occupancy_status', 'channel', 'property_state', 'property_type', \n",
    "           'loan_purpose', 'mortgage_insurance_type', 'servicer_default_grp',\n",
    "           'servicer_prepay_grp', 'vintage_yr', 'dq_status']\n",
    "\n",
    "CATCOLS = ['occupancy_status', 'channel', 'property_type']\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_cols = ['validation_flag','test_train']\n",
    "#testdata = pd.read_csv(test, index_col=False, nrows=(1*10**5),usecols = lambda column:column not in \n",
    "#skip_cols)\n",
    "traindata = pd.read_csv(train, index_col=False, nrows=(1*10**6),usecols = lambda column:column not in \n",
    "skip_cols)\n",
    "validata = pd.read_csv(valid, index_col=False, nrows=(4*10**5),usecols = lambda column:column not in \n",
    "skip_cols)\n",
    "hist = traindata #pd.concat([traindata,testdata,validata]) \n",
    "hist = pd.get_dummies(hist, columns=CATCOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real, dev_real = sklearn.model_selection.train_test_split(validata, test_size = 0.5, train_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.get_dummies(test_real,columns=CATCOLS)\n",
    "devdata = pd.get_dummies(dev_real,columns=CATCOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata.prepay_flg.values.sum()\n",
    "testdata.default_flg.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validata.prepay_flg.values.sum()\n",
    "devdata.default_flg.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.groupby(['mortgage_insurance_type']).count()['loan_sequence_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata.groupby(['mortgage_insurance_type']).count()['loan_sequence_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_XY(hist):\n",
    "    X = None\n",
    "    Y = None\n",
    "    data = np.concatenate((np.arange(START, START + TIMERANGE).reshape(-1,1), np.ones((TIMERANGE,1))), axis=1)\n",
    "    dummy_df = pd.DataFrame(data, columns=['loan_age', 'removed'])\n",
    "    lsn = []\n",
    "\n",
    "    for loan_num, group_df in hist.groupby(['loan_sequence_number']):\n",
    "        # Clean up instances where default flag is raise but loan persists\n",
    "        if group_df[group_df['default_flg'] == 1].shape[0] > 1:\n",
    "            first_idx = group_df[group_df['default_flg'] == 1]['default_flg'].index[0]\n",
    "            group_df = group_df.loc[:first_idx,:]\n",
    "\n",
    "        tmpY = group_df[['prepay_flg', 'default_flg', 'loan_age']]\n",
    "        \n",
    "        if not tmpY.iloc[:TIMERANGE,[0,1]].any().any():\n",
    "            lastYVal = tmpY[TIMERANGE:TIMERANGE+12].any()[0:2] * 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        tmpY['current'] = True\n",
    "        tmpY['current'].iloc[-1] = ~tmpY['prepay_flg'].astype(bool).iloc[-1] & ~tmpY['default_flg'].astype(bool).iloc[-1]\n",
    "        tmpY = dummy_df.merge(tmpY, on='loan_age', how='left').fillna(0)\n",
    "        if not tmpY.iloc[:,[2,3]].any().any():\n",
    "            tmpY.iloc[TIMERANGE-1,[2,3]] = lastYVal\n",
    "        tmpY = tmpY.drop(['loan_age'], axis=1)\n",
    "        tmpY = tmpY.astype(bool)\n",
    "        tmpY.loc[:,'removed'] = ~tmpY['current'] & ~tmpY['prepay_flg'] & ~tmpY['default_flg']\n",
    "        tmpY = np.array(tmpY).reshape((1, tmpY.shape[0], tmpY.shape[1]))\n",
    "\n",
    "        lsn.append(loan_num)\n",
    "        tmpX = group_df.drop(['loan_sequence_number', 'prepay_flg', 'default_flg'], axis=1)\n",
    "        tmpX = dummy_df.merge(tmpX, on='loan_age', how='left').fillna(0)\n",
    "        tmpX = np.array(tmpX).reshape((1, tmpX.shape[0], tmpX.shape[1]))\n",
    "\n",
    "        if X is not None:\n",
    "            X = np.append(X, tmpX, axis=0)\n",
    "            Y = np.append(Y, tmpY, axis=0)\n",
    "        else:\n",
    "            X = tmpX\n",
    "            Y = tmpY\n",
    "    return (X,Y,lsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X,Y, lsn = generate_XY(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######This is only for writing....No need to run everytime#######\n",
    "with open('devdata.pkl', 'wb') as f:\n",
    "    pickle.dump((Xdev,Ydev,lsntest), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######This is only for reading....No need to run everytime#######\n",
    "\n",
    "with open('traindata.pkl', 'rb') as f: \n",
    "    X2, Y2, lsn2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29702, 20, 45)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "Xtest,Ytest, lsntest = generate_XY(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "Xdev,Ydev, lsndev = generate_XY(devdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29704, 20, 45)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loan_num, group_df in hist.groupby(['loan_sequence_number']):\n",
    "\n",
    "        if group_df[group_df['default_flg'] == 1].shape[0] > 1:\n",
    "            first_idx = group_df[group_df['default_flg'] == 1]['default_flg'].index[0]\n",
    "            group_df = group_df.loc[:first_idx,:]\n",
    "\n",
    "        if group_df.shape[0] > 10:\n",
    "            tmpY = group_df[['prepay_flg', 'default_flg', 'loan_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout:0.15\tbatchsize:32\toptimzer:rmsprop\tHidden_U:30\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 50s 1ms/sample - loss: 0.0071 - categorical_accuracy: 0.5704 - val_loss: 0.0043 - val_categorical_accuracy: 0.8727\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 46s 1ms/sample - loss: 0.0046 - categorical_accuracy: 0.8513 - val_loss: 0.0050 - val_categorical_accuracy: 0.8272\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 42s 1ms/sample - loss: 0.0040 - categorical_accuracy: 0.8793 - val_loss: 0.0037 - val_categorical_accuracy: 0.8616\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 43s 1ms/sample - loss: 0.0038 - categorical_accuracy: 0.8943 - val_loss: 0.0037 - val_categorical_accuracy: 0.8543\n",
      "dropout:0.15\tbatchsize:32\toptimzer:rmsprop\tHidden_U:40\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 64s 2ms/sample - loss: 0.0060 - categorical_accuracy: 0.7371 - val_loss: 0.0024 - val_categorical_accuracy: 0.8841\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 49s 1ms/sample - loss: 0.0041 - categorical_accuracy: 0.8935 - val_loss: 0.0020 - val_categorical_accuracy: 0.8852\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 52s 1ms/sample - loss: 0.0036 - categorical_accuracy: 0.9328 - val_loss: 0.0016 - val_categorical_accuracy: 0.9123\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 52s 1ms/sample - loss: 0.0035 - categorical_accuracy: 0.9471 - val_loss: 9.5468e-04 - val_categorical_accuracy: 0.9809\n",
      "dropout:0.15\tbatchsize:32\toptimzer:adam\tHidden_U:30\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 53s 1ms/sample - loss: 0.0057 - categorical_accuracy: 0.7706 - val_loss: 0.0040 - val_categorical_accuracy: 0.8357\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 51s 1ms/sample - loss: 0.0039 - categorical_accuracy: 0.8972 - val_loss: 0.0043 - val_categorical_accuracy: 0.7767\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 50s 1ms/sample - loss: 0.0036 - categorical_accuracy: 0.9182 - val_loss: 0.0038 - val_categorical_accuracy: 0.7886\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 48s 1ms/sample - loss: 0.0034 - categorical_accuracy: 0.9328 - val_loss: 0.0036 - val_categorical_accuracy: 0.8004\n",
      "dropout:0.15\tbatchsize:32\toptimzer:adam\tHidden_U:40\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 57s 1ms/sample - loss: 0.0064 - categorical_accuracy: 0.6933 - val_loss: 0.0025 - val_categorical_accuracy: 0.9028\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 53s 1ms/sample - loss: 0.0042 - categorical_accuracy: 0.8866 - val_loss: 0.0016 - val_categorical_accuracy: 0.9190\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 53s 1ms/sample - loss: 0.0036 - categorical_accuracy: 0.9094 - val_loss: 0.0022 - val_categorical_accuracy: 0.8983\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 55s 1ms/sample - loss: 0.0035 - categorical_accuracy: 0.9202 - val_loss: 0.0021 - val_categorical_accuracy: 0.9102\n",
      "dropout:0.15\tbatchsize:64\toptimzer:rmsprop\tHidden_U:30\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 35s 868us/sample - loss: 0.0067 - categorical_accuracy: 0.6612 - val_loss: 0.0040 - val_categorical_accuracy: 0.8234\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 29s 712us/sample - loss: 0.0045 - categorical_accuracy: 0.8882 - val_loss: 0.0038 - val_categorical_accuracy: 0.7681\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 29s 708us/sample - loss: 0.0037 - categorical_accuracy: 0.9256 - val_loss: 0.0032 - val_categorical_accuracy: 0.7702\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 28s 683us/sample - loss: 0.0036 - categorical_accuracy: 0.9356 - val_loss: 0.0026 - val_categorical_accuracy: 0.8013\n",
      "dropout:0.15\tbatchsize:64\toptimzer:rmsprop\tHidden_U:40\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n",
      "40521/40521 [==============================] - 37s 917us/sample - loss: 0.0063 - categorical_accuracy: 0.7046 - val_loss: 0.0045 - val_categorical_accuracy: 0.8533\n",
      "Epoch 2/4\n",
      "40521/40521 [==============================] - 30s 741us/sample - loss: 0.0044 - categorical_accuracy: 0.8640 - val_loss: 0.0039 - val_categorical_accuracy: 0.8709\n",
      "Epoch 3/4\n",
      "40521/40521 [==============================] - 33s 824us/sample - loss: 0.0039 - categorical_accuracy: 0.8871 - val_loss: 0.0029 - val_categorical_accuracy: 0.8814\n",
      "Epoch 4/4\n",
      "40521/40521 [==============================] - 30s 753us/sample - loss: 0.0036 - categorical_accuracy: 0.9198 - val_loss: 0.0022 - val_categorical_accuracy: 0.8868\n",
      "dropout:0.15\tbatchsize:64\toptimzer:adam\tHidden_U:30\n",
      "Train on 40521 samples, validate on 29693 samples\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning\n",
    "hiddensizes = [15,20, 30, 40]\n",
    "dropouts = [0,0.8,0.15,0.2]\n",
    "batch_sizes = [32,64,128]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "for dropout in dropouts:\n",
    "    for batch_size in batch_sizes:\n",
    "        for optimizer in optimizers:\n",
    "            for hidden in hiddensizes:\n",
    "                print('dropout:' + str(dropout) + '\\t' + 'batchsize:' + str(batch_size) + '\\t' + 'optimzer:' + str(optimizer)  + '\\t' + 'Hidden_U:' + str(hidden))\n",
    "\n",
    "                regressor = Sequential()\n",
    "                #hiddensize1 = X.shape[2]\n",
    "\n",
    "                regressor.add(LSTM(units = hidden, dropout=dropout, return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n",
    "                regressor.add(LSTM(units = hidden, dropout=dropout, return_sequences = True))\n",
    "                #regressor.add(LSTM(units = hiddensize1, dropout=0.2, return_sequences = True))\n",
    "\n",
    "                regressor.add(Dense(units = 4, activation='softmax'))\n",
    "                weights = np.array([0.005,0.24,0.75,0.005])\n",
    "                #weights = np.ones((4,))*1.0\n",
    "                regressor.compile(optimizer = optimizer, loss = weighted_categorical_crossentropy(weights), metrics = ['categorical_accuracy'])\n",
    "                regressor.fit(X, Y*1.0,batch_size=batch_size, epochs=4, verbose=1, validation_data=(Xtest, Ytest*1.0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout:0.08\tbatchsize:64\toptimzer: RMSprop\tHidden_U:20\n",
      "Train on 40521 samples, validate on 29704 samples\n",
      "Epoch 1/10\n",
      "40521/40521 [==============================] - 29s 717us/sample - loss: 0.0065 - categorical_accuracy: 0.6945 - val_loss: 0.0030 - val_categorical_accuracy: 0.8894\n",
      "Epoch 2/10\n",
      "40521/40521 [==============================] - 26s 636us/sample - loss: 0.0041 - categorical_accuracy: 0.8872 - val_loss: 0.0029 - val_categorical_accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "40521/40521 [==============================] - 27s 672us/sample - loss: 0.0037 - categorical_accuracy: 0.9179 - val_loss: 0.0018 - val_categorical_accuracy: 0.9258\n",
      "Epoch 4/10\n",
      "40521/40521 [==============================] - 27s 671us/sample - loss: 0.0034 - categorical_accuracy: 0.9334 - val_loss: 0.0015 - val_categorical_accuracy: 0.9387\n",
      "Epoch 5/10\n",
      "40521/40521 [==============================] - 29s 715us/sample - loss: 0.0031 - categorical_accuracy: 0.9430 - val_loss: 0.0012 - val_categorical_accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "40521/40521 [==============================] - 27s 669us/sample - loss: 0.0030 - categorical_accuracy: 0.9485 - val_loss: 0.0012 - val_categorical_accuracy: 0.9384\n",
      "Epoch 7/10\n",
      "40521/40521 [==============================] - 29s 705us/sample - loss: 0.0030 - categorical_accuracy: 0.9524 - val_loss: 0.0012 - val_categorical_accuracy: 0.9413\n",
      "Epoch 8/10\n",
      "40521/40521 [==============================] - 30s 743us/sample - loss: 0.0029 - categorical_accuracy: 0.9558 - val_loss: 0.0011 - val_categorical_accuracy: 0.9475\n",
      "Epoch 9/10\n",
      "40521/40521 [==============================] - 28s 681us/sample - loss: 0.0028 - categorical_accuracy: 0.9594 - val_loss: 0.0010 - val_categorical_accuracy: 0.9504\n",
      "Epoch 10/10\n",
      "40521/40521 [==============================] - 27s 667us/sample - loss: 0.0028 - categorical_accuracy: 0.9601 - val_loss: 0.0011 - val_categorical_accuracy: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc53d8fe810>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('dropout:0.08'  + '\\t' + 'batchsize:64' +  '\\t' + 'optimzer: RMSprop' + '\\t' + 'Hidden_U:20' )\n",
    "\n",
    "regressor = Sequential()\n",
    "#hiddensize1 = X.shape[2]\n",
    "\n",
    "regressor.add(LSTM(units = 20, dropout=0.08, return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n",
    "regressor.add(LSTM(units = 20, dropout=0.08, return_sequences = True))\n",
    "#regressor.add(LSTM(units = hiddensize1, dropout=0.2, return_sequences = True))\n",
    "\n",
    "regressor.add(Dense(units = 4, activation='softmax'))\n",
    "weights = np.array([0.005,0.24,0.75,0.005])\n",
    "#weights = np.ones((4,))*1.0\n",
    "regressor.compile(optimizer = 'rmsprop', loss = weighted_categorical_crossentropy(weights), metrics = ['categorical_accuracy'])\n",
    "regressor.fit(X, Y*1.0,batch_size=64, epochs=10, verbose=1, validation_data=(Xdev, Ydev*1.0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('regressor.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor2 = tf.keras.models.load_model('regressor.h5', custom_objects={'loss':weighted_categorical_crossentropy(weights)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest,Ytest, lsntest = generate_XY(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YpredTest = regressor.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdev,Ydev, lsndev = generate_XY(validata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2272\n",
    "Ypred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[hist.loan_sequence_number==lsn[idx]][['prepay_flg','default_flg','loan_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[hist.default_flg==1]['loan_sequence_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(lsn) == 668620845349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
